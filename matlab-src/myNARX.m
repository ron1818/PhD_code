function [ Y_hat ] = myNARX( X, Y, inputDelays, hiddenLayerSize, RATIO)
% Solve an Input-Output Time-Series Problem with a Time Delay Neural Network
% Script generated by NTSTOOL.
% Created Thu Jan 16 16:15:41 SGT 2014
%
% This script assumes these variables are defined:
%
%   IMF - input time series.
%   scaled_data - target time series.

inputSeries = tonndata(X,false,false);
targetSeries = tonndata(Y,false,false);

% Create a Time Delay Network
% inputDelays = 0:47;
% hiddenLayerSize = 24;
net = timedelaynet(inputDelays,hiddenLayerSize);

% Choose Input and Output Pre/Post-Processing Functions
% For a list of all processing functions type: help nnprocess
net.inputs{1}.processFcns = {'removeconstantrows','mapminmax'};
net.outputs{2}.processFcns = {'removeconstantrows','mapminmax'};

% Prepare the Data for Training and Simulation
% The function PREPARETS prepares timeseries data for a particular network,
% shifting time by the minimum amount to fill input states and layer states.
% Using PREPARETS allows you to keep your original time series data unchanged, while
% easily customizing it for networks with differing numbers of delays, with
% open loop or closed loop feedback modes.
[inputs,inputStates,layerStates,targets] = preparets(net,inputSeries,targetSeries);

% Setup Division of Data for Training, Validation, Testing
% For a list of all data division functions type: help nndivide
% net.divideFcn = 'dividerand';  % Divide data randomly
% net.divideMode = 'time';  % Divide up every value
% net.divideParam.trainRatio = 60/100;
% net.divideParam.valRatio = 20/100;
% net.divideParam.testRatio = 20/100;
net.divideFcn = 'dividerand';  % Divide data randomly
net.divideMode = 'time';  % Divide up every value
net.divideParam.trainRatio = RATIO(1);
net.divideParam.valRatio = RATIO(2);
net.divideParam.testRatio = RATIO(3);

% For help on training function 'trainlm' type: help trainlm
% For a list of all training functions type: help nntrain
net.trainFcn = 'trainlm';  % Levenberg-Marquardt

% Choose a Performance Function
% For a list of all performance functions type: help nnperformance
net.performFcn = 'mse';  % Mean squared error

% Don't show NN window
net.trainParam.showWindow=0;

% Choose Plot Functions
% For a list of all plot functions type: help nnplot
net.plotFcns = {'plotperform','plottrainstate','plotresponse', ...
  'ploterrcorr', 'plotinerrcorr'};


% Train the Network
[net,tr] = train(net,inputs,targets,inputStates,layerStates);

% Test the Network
outputs = net(inputs,inputStates,layerStates);
Y_hat=cell2mat(outputs)';
% errors = gsubtract(targets,outputs);
% performance = perform(net,targets,outputs)
% 
% % Recalculate Training, Validation and Test Performance
% trainTargets = gmultiply(targets,tr.trainMask);
% valTargets = gmultiply(targets,tr.valMask);
% testTargets = gmultiply(targets,tr.testMask);
% trainPerformance = perform(net,trainTargets,outputs)
% valPerformance = perform(net,valTargets,outputs)
% testPerformance = perform(net,testTargets,outputs)

% View the Network
% view(net);

% Plots
% Uncomment these lines to enable various plots.
%figure, plotperform(tr)
%figure, plottrainstate(tr)
%figure, plotresponse(targets,outputs)
%figure, ploterrcorr(errors)
%figure, plotinerrcorr(inputs,errors)

% % Early Prediction Network
% % For some applications it helps to get the prediction a timestep early.
% % The original network returns predicted y(t+1) at the same time it is given x(t+1).
% % For some applications such as decision making, it would help to have predicted
% % y(t+1) once x(t) is available, but before the actual y(t+1) occurs.
% % The network can be made to return its output a timestep early by removing one delay
% % so that its minimal tap delay is now 0 instead of 1.  The new network returns the
% % same outputs as the original network, but outputs are shifted left one timestep.
% nets = removedelay(net);
% [xs,xis,ais,ts] = preparets(nets,inputSeries,targetSeries);
% ys = nets(xs,xis,ais);
% earlyPredictPerformance = perform(net,tc,yc)
end